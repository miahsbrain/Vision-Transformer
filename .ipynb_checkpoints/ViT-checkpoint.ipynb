{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e211a83-9784-49b5-ba28-99cf44e4c7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34b04eae-740e-4649-b657-b7bb5e3ce790",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "patchsize = 16\n",
    "latentsize = 768\n",
    "n_channels = 3\n",
    "num_heads = 12\n",
    "dropout = 0.1\n",
    "num_classes = 10\n",
    "size = 224\n",
    "num_encoders = 4\n",
    "\n",
    "epochs = 10\n",
    "base_lr = 10e-3\n",
    "weight_decay = 0.03\n",
    "batchsize = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3ec4eb9-7290-439f-92d0-72995f529c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbedding(nn.Module):\n",
    "    def __init__(self, patchsize=patchsize, n_channels=n_channels, device=device, latentsize=latentsize, batchsize=batchsize):\n",
    "        super().__init__()\n",
    "        self.patchsize = patchsize\n",
    "        self.n_channels = n_channels\n",
    "        self.device = device\n",
    "        self.latentsize = latentsize\n",
    "        self.batchsize = batchsize\n",
    "        self.inputsize = self.patchsize * self.patchsize * self.n_channels\n",
    "\n",
    "        # Linear projection\n",
    "        self.linPro = nn.Linear(self.inputsize, self.latentsize)\n",
    "        # Class token\n",
    "        self.class_tok = nn.Parameter(torch.randn(size=[self.batchsize, 1, self.latentsize])).to(self.device)\n",
    "        # Positional embedding\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(size=[self.batchsize, 1, self.latentsize])).to(self.device)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        input_data = input_data.to(self.device)\n",
    "\n",
    "        # Get patches\n",
    "        patches = einops.rearrange(input_data, 'b (w w1) (h h1) c -> b (w h) (w1 h1 c)', w1=self.patchsize, h1=self.patchsize)\n",
    "        print(input_data.shape)\n",
    "        print(patches.shape)\n",
    "        linear_proj = self.linPro(patches).to(self.device)\n",
    "        b, n, _ = linear_proj.shape\n",
    "        linear_proj = torch.cat([self.class_tok, linear_proj], dim=1)\n",
    "        # print(linear_proj.shape)\n",
    "        pos_embed = einops.repeat(self.pos_embedding, 'b 1 d -> b m d', m=n+1)\n",
    "        # print(pos_embed.shape)\n",
    "        linear_proj += pos_embed\n",
    "        return linear_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58e14c45-654c-4fdd-abb7-8b27163f5aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 224, 224, 3])\n",
      "torch.Size([4, 196, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.2408, -0.2792,  2.5888,  ...,  0.4907,  0.6831,  1.8021],\n",
       "         [ 1.4117,  2.2739,  1.2022,  ..., -2.0835,  0.9015,  2.7208],\n",
       "         [-0.0323,  2.2394,  0.0081,  ..., -0.0370,  1.1567,  2.3511],\n",
       "         ...,\n",
       "         [ 0.9875,  2.4814,  1.1338,  ..., -1.5002,  2.0912,  2.8131],\n",
       "         [ 1.0445,  1.3634,  0.1274,  ...,  0.4798, -0.2692,  2.1926],\n",
       "         [ 1.1807,  2.2859,  1.1538,  ..., -0.4362,  0.6950,  0.7023]],\n",
       "\n",
       "        [[ 0.9836,  0.6614, -2.2089,  ..., -0.4724,  1.3556, -0.4839],\n",
       "         [ 0.6325, -0.8714, -1.7137,  ...,  1.0885, -0.2708, -0.6648],\n",
       "         [ 1.9617, -0.0686, -0.0846,  ...,  0.4206, -0.1544, -0.6950],\n",
       "         ...,\n",
       "         [ 0.5441, -0.9152, -0.4645,  ...,  0.2636, -0.7799,  0.4371],\n",
       "         [ 1.1925, -0.1778, -0.6451,  ..., -0.4484,  0.0733,  0.2611],\n",
       "         [ 0.5775,  0.6868, -0.9261,  ..., -0.4567, -0.5782, -0.0293]],\n",
       "\n",
       "        [[-0.5908, -1.4816,  0.6578,  ...,  2.2974,  0.0587, -1.0836],\n",
       "         [-0.1214,  2.5687,  0.0375,  ...,  0.8430,  0.4711,  0.4526],\n",
       "         [-1.2926,  2.1720, -0.1296,  ...,  0.9296,  0.8908, -0.9529],\n",
       "         ...,\n",
       "         [-0.0206,  1.9567, -1.2511,  ...,  1.8908,  0.3829, -0.0387],\n",
       "         [ 0.0250,  1.0395, -1.2602,  ...,  0.7278,  1.0360,  0.1526],\n",
       "         [-0.1865,  2.0139,  0.4558,  ...,  0.7718, -0.1775,  0.1500]],\n",
       "\n",
       "        [[-1.4058, -3.2747, -0.6868,  ..., -1.4840, -0.3663,  0.2902],\n",
       "         [-1.6186, -3.1717, -0.5533,  ..., -0.5359, -0.7661,  0.2295],\n",
       "         [-1.0862, -2.4436,  0.2238,  ..., -0.0573,  0.4167,  1.9743],\n",
       "         ...,\n",
       "         [-1.0579, -2.5654,  0.2272,  ..., -0.8606,  0.2760,  0.7591],\n",
       "         [-0.7230, -2.8126, -0.6970,  ..., -0.1359, -1.8036,  1.6386],\n",
       "         [-0.6507, -3.5926, -0.3228,  ...,  0.0523,  0.3175,  0.2592]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = InputEmbedding()\n",
    "test_data = torch.randn(size=[batchsize, size, size, 3])\n",
    "test_model(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7fbd27a4-a10c-46fd-891f-9d92acb67a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 224, 224, 3])\n",
      "torch.Size([4, 196, 768])\n"
     ]
    }
   ],
   "source": [
    "embed_test = test_model(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3aa237e4-3985-4ce2-a6c0-8d827ba4f066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the encoder block\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, latentsize=latentsize, num_heads=num_heads, dropout=dropout):\n",
    "        super().__init__()\n",
    "        self.latentsize = latentsize\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.norm = nn.LayerNorm(self.latentsize)\n",
    "        self.multihead = nn.MultiheadAttention(self.latentsize, self.num_heads, dropout)\n",
    "        self.enc_mlp = nn.Sequential(\n",
    "            nn.Linear(self.latentsize, self.latentsize*4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(self.latentsize*4, self.latentsize),\n",
    "            nn.Dropout(self.dropout)\n",
    "        )\n",
    "    def forward(self, embeded_patches):\n",
    "        firstnum_out = self.norm(embeded_patches)\n",
    "        attention_out = self.multihead(firstnum_out, firstnum_out, firstnum_out)[0]\n",
    "\n",
    "        # First residual connection\n",
    "        first_added = attention_out + embeded_patches\n",
    "\n",
    "        # Second normalization\n",
    "        secondnum_out = self.norm(first_added)\n",
    "        mlp_out = self.enc_mlp(secondnum_out)\n",
    "\n",
    "        return mlp_out + first_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "adc85cde-2611-48a5-8131-8cd470cb344e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5774e+00, -2.7442e-01,  2.6889e+00,  ...,  4.6754e-01,\n",
       "           8.1979e-01,  2.1240e+00],\n",
       "         [ 1.9769e+00,  2.4141e+00,  1.4652e+00,  ..., -1.8866e+00,\n",
       "           1.0184e+00,  2.8054e+00],\n",
       "         [ 5.7436e-01,  2.1912e+00,  2.9865e-01,  ..., -3.6936e-01,\n",
       "           1.5827e+00,  2.7564e+00],\n",
       "         ...,\n",
       "         [ 1.6764e+00,  2.6678e+00,  1.5635e+00,  ..., -2.1379e+00,\n",
       "           2.3772e+00,  3.0827e+00],\n",
       "         [ 1.3878e+00,  1.6331e+00,  4.2734e-01,  ...,  3.3520e-01,\n",
       "          -2.5855e-01,  2.5211e+00],\n",
       "         [ 1.7888e+00,  2.3963e+00,  1.6377e+00,  ..., -7.3307e-01,\n",
       "           9.5558e-01,  1.0482e+00]],\n",
       "\n",
       "        [[ 1.4819e+00,  8.2320e-01, -2.2374e+00,  ..., -2.8348e-01,\n",
       "           8.3265e-01,  4.6484e-01],\n",
       "         [ 8.9111e-01, -7.0421e-01, -1.4706e+00,  ...,  1.2423e+00,\n",
       "          -8.2688e-01, -2.3324e-01],\n",
       "         [ 2.5250e+00,  5.2555e-02,  2.5667e-02,  ...,  5.5273e-01,\n",
       "          -2.7624e-01, -2.8777e-01],\n",
       "         ...,\n",
       "         [ 8.9363e-01, -5.9552e-01, -1.1885e-01,  ...,  4.6188e-01,\n",
       "          -7.6965e-01,  4.1843e-01],\n",
       "         [ 1.4920e+00,  2.7939e-01, -6.9419e-01,  ..., -7.3303e-01,\n",
       "          -3.9973e-01,  3.0183e-01],\n",
       "         [ 6.5049e-01,  1.0081e+00, -7.3698e-01,  ..., -1.3991e-01,\n",
       "          -1.0819e+00,  1.3088e-01]],\n",
       "\n",
       "        [[-2.8874e-01, -1.5776e+00,  7.9900e-01,  ...,  2.6321e+00,\n",
       "          -6.9145e-02, -6.3867e-01],\n",
       "         [-9.6304e-02,  2.8582e+00,  5.1668e-01,  ...,  1.0190e+00,\n",
       "           3.0435e-01,  4.2330e-01],\n",
       "         [-1.3360e+00,  1.8084e+00,  2.7860e-02,  ...,  1.1319e+00,\n",
       "           9.9629e-01, -6.7537e-01],\n",
       "         ...,\n",
       "         [ 6.2726e-01,  1.9392e+00, -7.7670e-01,  ...,  1.9976e+00,\n",
       "           5.9783e-01,  9.7469e-02],\n",
       "         [ 1.8676e-01,  1.1264e+00, -1.0258e+00,  ...,  7.3929e-01,\n",
       "           6.8308e-01, -3.8283e-02],\n",
       "         [ 2.1762e-01,  1.8836e+00,  9.8387e-01,  ...,  9.1381e-01,\n",
       "          -1.9335e-01,  4.1849e-01]],\n",
       "\n",
       "        [[-7.7613e-01, -3.2389e+00, -3.9502e-01,  ..., -9.2154e-01,\n",
       "          -5.2593e-02,  5.2595e-01],\n",
       "         [-1.1741e+00, -2.9801e+00, -4.3744e-01,  ...,  2.1762e-01,\n",
       "          -5.3983e-01,  3.7311e-01],\n",
       "         [-6.1930e-01, -2.3342e+00,  1.8442e-01,  ...,  6.8558e-01,\n",
       "           4.5697e-01,  1.9666e+00],\n",
       "         ...,\n",
       "         [-7.2880e-01, -2.4053e+00,  7.0553e-01,  ..., -3.7536e-01,\n",
       "           3.6852e-01,  1.0418e+00],\n",
       "         [-5.2350e-01, -2.8691e+00, -9.0859e-01,  ...,  6.8360e-03,\n",
       "          -1.7438e+00,  1.8431e+00],\n",
       "         [-4.7486e-01, -3.5520e+00, -1.3525e-03,  ...,  5.3730e-01,\n",
       "           1.5182e-01,  5.6608e-01]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_test = EncoderBlock()\n",
    "enc_test(embed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a20de8d-f565-4070-bd24-b11e4b87ecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put everything together\n",
    "class Vit(nn.Module):\n",
    "    def __init__(self, num_encoders=num_encoders, latentsize=latentsize, deice=device, num_classes=num_classes, dropout=dropout):\n",
    "        super().__init__()\n",
    "        self.num_encoders = num_encoders\n",
    "        self.latentsize = self.latentsize\n",
    "        self.device = device\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = InputEmbedding()\n",
    "        self.encStack = nn.ModuleList([EncoderBlock() for _ in range(self.num_encoders)])\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(self.latentsize),\n",
    "            nn.Linear(self.latentsize, self.latentsize),\n",
    "            nn.Linear(self.latentsize, self.num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, test_input):\n",
    "        enc_output = self.embedding(test_input)\n",
    "\n",
    "        for enc_layer in self.encStack:\n",
    "            enc_output = enc_layer(enc_output)\n",
    "\n",
    "        cls_tok_embed = enc_output[:, 0]\n",
    "        return self.mlp_head(cls_tok_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aeeca8-70d1-42c1-b4d2-7b3a2ac74a04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
