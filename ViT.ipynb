{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e211a83-9784-49b5-ba28-99cf44e4c7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34b04eae-740e-4649-b657-b7bb5e3ce790",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "patchsize = 16\n",
    "latentsize = 768\n",
    "n_channels = 3\n",
    "num_heads = 12\n",
    "dropout = 0.1\n",
    "num_classes = 10\n",
    "size = 224\n",
    "num_encoders = 4\n",
    "\n",
    "epochs = 10\n",
    "base_lr = 10e-3\n",
    "weight_decay = 0.03\n",
    "batchsize = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3ec4eb9-7290-439f-92d0-72995f529c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbedding(nn.Module):\n",
    "    def __init__(self, patchsize=patchsize, n_channels=n_channels, device=device, latentsize=latentsize, batchsize=batchsize):\n",
    "        super().__init__()\n",
    "        self.patchsize = patchsize\n",
    "        self.n_channels = n_channels\n",
    "        self.device = device\n",
    "        self.latentsize = latentsize\n",
    "        self.batchsize = batchsize\n",
    "        self.inputsize = self.patchsize * self.patchsize * self.n_channels\n",
    "\n",
    "        # Linear projection\n",
    "        self.linPro = nn.Linear(self.inputsize, self.latentsize)\n",
    "        # Class token\n",
    "        self.class_tok = nn.Parameter(torch.randn(size=[self.batchsize, 1, self.latentsize])).to(self.device)\n",
    "        # Positional embedding\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(size=[self.batchsize, 1, self.latentsize])).to(self.device)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        input_data = input_data.to(self.device)\n",
    "\n",
    "        # Get patches\n",
    "        patches = einops.rearrange(input_data, 'b (w w1) (h h1) c -> b (w h) (w1 h1 c)', w1=self.patchsize, h1=self.patchsize)\n",
    "        print(input_data.shape)\n",
    "        print(patches.shape)\n",
    "        linear_proj = self.linPro(patches).to(self.device)\n",
    "        b, n, _ = linear_proj.shape\n",
    "        linear_proj = torch.cat([self.class_tok, linear_proj], dim=1)\n",
    "        # print(linear_proj.shape)\n",
    "        pos_embed = einops.repeat(self.pos_embedding, 'b 1 d -> b m d', m=n+1)\n",
    "        # print(pos_embed.shape)\n",
    "        linear_proj += pos_embed\n",
    "        return linear_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58e14c45-654c-4fdd-abb7-8b27163f5aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 224, 224, 3])\n",
      "torch.Size([4, 196, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.2408, -0.2792,  2.5888,  ...,  0.4907,  0.6831,  1.8021],\n",
       "         [ 1.4117,  2.2739,  1.2022,  ..., -2.0835,  0.9015,  2.7208],\n",
       "         [-0.0323,  2.2394,  0.0081,  ..., -0.0370,  1.1567,  2.3511],\n",
       "         ...,\n",
       "         [ 0.9875,  2.4814,  1.1338,  ..., -1.5002,  2.0912,  2.8131],\n",
       "         [ 1.0445,  1.3634,  0.1274,  ...,  0.4798, -0.2692,  2.1926],\n",
       "         [ 1.1807,  2.2859,  1.1538,  ..., -0.4362,  0.6950,  0.7023]],\n",
       "\n",
       "        [[ 0.9836,  0.6614, -2.2089,  ..., -0.4724,  1.3556, -0.4839],\n",
       "         [ 0.6325, -0.8714, -1.7137,  ...,  1.0885, -0.2708, -0.6648],\n",
       "         [ 1.9617, -0.0686, -0.0846,  ...,  0.4206, -0.1544, -0.6950],\n",
       "         ...,\n",
       "         [ 0.5441, -0.9152, -0.4645,  ...,  0.2636, -0.7799,  0.4371],\n",
       "         [ 1.1925, -0.1778, -0.6451,  ..., -0.4484,  0.0733,  0.2611],\n",
       "         [ 0.5775,  0.6868, -0.9261,  ..., -0.4567, -0.5782, -0.0293]],\n",
       "\n",
       "        [[-0.5908, -1.4816,  0.6578,  ...,  2.2974,  0.0587, -1.0836],\n",
       "         [-0.1214,  2.5687,  0.0375,  ...,  0.8430,  0.4711,  0.4526],\n",
       "         [-1.2926,  2.1720, -0.1296,  ...,  0.9296,  0.8908, -0.9529],\n",
       "         ...,\n",
       "         [-0.0206,  1.9567, -1.2511,  ...,  1.8908,  0.3829, -0.0387],\n",
       "         [ 0.0250,  1.0395, -1.2602,  ...,  0.7278,  1.0360,  0.1526],\n",
       "         [-0.1865,  2.0139,  0.4558,  ...,  0.7718, -0.1775,  0.1500]],\n",
       "\n",
       "        [[-1.4058, -3.2747, -0.6868,  ..., -1.4840, -0.3663,  0.2902],\n",
       "         [-1.6186, -3.1717, -0.5533,  ..., -0.5359, -0.7661,  0.2295],\n",
       "         [-1.0862, -2.4436,  0.2238,  ..., -0.0573,  0.4167,  1.9743],\n",
       "         ...,\n",
       "         [-1.0579, -2.5654,  0.2272,  ..., -0.8606,  0.2760,  0.7591],\n",
       "         [-0.7230, -2.8126, -0.6970,  ..., -0.1359, -1.8036,  1.6386],\n",
       "         [-0.6507, -3.5926, -0.3228,  ...,  0.0523,  0.3175,  0.2592]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = InputEmbedding()\n",
    "test_data = torch.randn(size=[batchsize, size, size, 3])\n",
    "test_model(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7fbd27a4-a10c-46fd-891f-9d92acb67a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 224, 224, 3])\n",
      "torch.Size([4, 196, 768])\n"
     ]
    }
   ],
   "source": [
    "embed_test = test_model(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3aa237e4-3985-4ce2-a6c0-8d827ba4f066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the encoder block\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, latentsize=latentsize, num_heads=num_heads, dropout=dropout):\n",
    "        super().__init__()\n",
    "        self.latentsize = latentsize\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.norm = nn.LayerNorm(self.latentsize)\n",
    "        self.multihead = nn.MultiheadAttention(self.latentsize, self.num_heads, dropout)\n",
    "        self.enc_mlp = nn.Sequential(\n",
    "            nn.Linear(self.latentsize, self.latentsize*4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(self.latentsize*4, self.latentsize),\n",
    "            nn.Dropout(self.dropout)\n",
    "        )\n",
    "    def forward(self, embeded_patches):\n",
    "        firstnum_out = self.norm(embeded_patches)\n",
    "        attention_out = self.multihead(firstnum_out, firstnum_out, firstnum_out)[0]\n",
    "\n",
    "        # First residual connection\n",
    "        first_added = attention_out + embeded_patches\n",
    "\n",
    "        # Second normalization\n",
    "        secondnum_out = self.norm(first_added)\n",
    "        mlp_out = self.enc_mlp(secondnum_out)\n",
    "\n",
    "        return mlp_out + first_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "adc85cde-2611-48a5-8131-8cd470cb344e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0016e+00,  6.2812e-02,  3.0892e+00,  ...,  2.0176e-01,\n",
       "           6.7085e-01,  1.6577e+00],\n",
       "         [ 1.4674e+00,  2.7044e+00,  1.2845e+00,  ..., -1.9885e+00,\n",
       "           6.8636e-01,  2.9603e+00],\n",
       "         [-4.2287e-01,  2.8176e+00,  9.9075e-02,  ...,  1.2024e-01,\n",
       "           1.3174e+00,  2.3826e+00],\n",
       "         ...,\n",
       "         [ 8.8647e-01,  2.7722e+00,  1.1649e+00,  ..., -1.4299e+00,\n",
       "           2.0114e+00,  3.3571e+00],\n",
       "         [ 1.0149e+00,  1.9444e+00,  3.4402e-01,  ...,  7.6743e-01,\n",
       "          -7.3242e-02,  2.6087e+00],\n",
       "         [ 1.2897e+00,  3.2423e+00,  1.0900e+00,  ..., -8.7784e-02,\n",
       "           5.7765e-01,  9.1872e-01]],\n",
       "\n",
       "        [[ 7.3546e-01,  1.2888e+00, -2.0278e+00,  ..., -4.8453e-01,\n",
       "           1.2954e+00, -6.6643e-01],\n",
       "         [ 4.2461e-01, -6.6702e-01, -1.7530e+00,  ...,  1.3552e+00,\n",
       "          -4.8863e-01, -8.9262e-01],\n",
       "         [ 1.6196e+00,  5.2400e-01,  4.3377e-02,  ...,  4.9845e-01,\n",
       "          -2.6144e-01, -6.5412e-01],\n",
       "         ...,\n",
       "         [ 4.1916e-01, -2.9149e-01, -6.7534e-01,  ..., -9.6590e-02,\n",
       "          -1.0775e+00,  7.2115e-01],\n",
       "         [ 1.0393e+00,  3.1188e-01, -2.8692e-01,  ..., -4.4949e-01,\n",
       "          -2.5048e-01,  6.2133e-01],\n",
       "         [ 3.0133e-01,  1.4043e+00, -6.1858e-01,  ..., -2.1280e-01,\n",
       "          -9.2427e-01, -4.8333e-02]],\n",
       "\n",
       "        [[-8.3063e-01, -1.3658e+00,  8.1015e-01,  ...,  1.4124e+00,\n",
       "          -3.1699e-01, -7.2108e-01],\n",
       "         [ 7.7364e-03,  2.8112e+00, -6.4841e-02,  ...,  9.5226e-01,\n",
       "          -1.5827e-01,  5.0110e-01],\n",
       "         [-1.8417e+00,  2.7700e+00, -5.2762e-01,  ...,  5.6420e-01,\n",
       "           3.2988e-01, -8.8945e-01],\n",
       "         ...,\n",
       "         [-1.3879e-01,  2.4060e+00, -1.2880e+00,  ...,  1.7515e+00,\n",
       "          -6.8716e-01,  2.9653e-01],\n",
       "         [-2.1905e-01,  1.3252e+00, -1.5661e+00,  ...,  8.5186e-01,\n",
       "           7.3438e-01,  6.0787e-01],\n",
       "         [-4.6495e-01,  2.6681e+00,  2.4311e-01,  ...,  8.5130e-01,\n",
       "          -4.6853e-01,  2.0929e-01]],\n",
       "\n",
       "        [[-1.5934e+00, -3.1829e+00, -4.9837e-01,  ..., -1.8600e+00,\n",
       "          -7.1969e-01,  1.1980e-01],\n",
       "         [-1.7680e+00, -3.0366e+00, -8.1159e-01,  ..., -3.7736e-01,\n",
       "          -9.5790e-01,  2.4444e-01],\n",
       "         [-1.4160e+00, -1.8471e+00,  3.2910e-01,  ..., -1.0862e-03,\n",
       "           1.8774e-01,  1.9778e+00],\n",
       "         ...,\n",
       "         [-1.2927e+00, -2.3133e+00,  2.0807e-01,  ..., -8.0353e-01,\n",
       "           1.8869e-02,  8.8656e-01],\n",
       "         [-1.2978e+00, -2.2270e+00, -5.2629e-01,  ..., -8.4970e-02,\n",
       "          -1.8800e+00,  1.9184e+00],\n",
       "         [-1.0816e+00, -3.1816e+00, -2.3647e-01,  ...,  3.7227e-01,\n",
       "           1.4548e-01,  2.1371e-01]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_test = EncoderBlock()\n",
    "enc_test(embed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a20de8d-f565-4070-bd24-b11e4b87ecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put everything together\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, num_encoders=num_encoders, latentsize=latentsize, deice=device, num_classes=num_classes, dropout=dropout):\n",
    "        super().__init__()\n",
    "        self.num_encoders = num_encoders\n",
    "        self.latentsize = self.latentsize\n",
    "        self.device = device\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = InputEmbedding()\n",
    "        self.encStack = nn.ModuleList([EncoderBlock() for _ in range(self.num_encoders)])\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(self.latentsize),\n",
    "            nn.Linear(self.latentsize, self.latentsize),\n",
    "            nn.Linear(self.latentsize, self.num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, test_input):\n",
    "        enc_output = self.embedding(test_input)\n",
    "\n",
    "        for enc_layer in self.encStack:\n",
    "            enc_output = enc_layer(enc_output)\n",
    "\n",
    "        cls_tok_embed = enc_output[:, 0]\n",
    "        return self.mlp_head(cls_tok_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aeeca8-70d1-42c1-b4d2-7b3a2ac74a04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
